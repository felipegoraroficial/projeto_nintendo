{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "474c0b61-5021-4b2c-a485-4038eca0aca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb13a4c6-881a-4bcc-9dea-e59b7e681949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "table_name = \"nintendodatabricks_workspace.silver.consoles_silver\"\n",
    "expected_columns = [\"codigo\", \"nome\", \"preco\", \"desconto\",\n",
    "                    \"numero_parcelas\", \"valor_prestacao\", \"origem\", \"link\",\n",
    "                    \"memoria\", \"oled\", \"extract\", \"recomendacao\"]\n",
    "\n",
    "expected_schema_types = {\n",
    "    \"codigo\": \"string\",\n",
    "    \"nome\": \"string\",\n",
    "    \"preco\": \"double\",\n",
    "    \"desconto\": \"double\",\n",
    "    \"numero_parcelas\": \"bigint\",\n",
    "    \"valor_prestacao\": \"double\",\n",
    "    \"origem\": \"string\",\n",
    "    \"link\": \"string\",\n",
    "    \"memoria\": \"string\",\n",
    "    \"oled\": \"string\",\n",
    "    \"extract\": \"timestamp\",\n",
    "    \"recomendacao\": \"string\"\n",
    "}\n",
    "\n",
    "def check_table_exists(table):\n",
    "    try:\n",
    "        spark.table(table)\n",
    "        return True\n",
    "    except AnalysisException:\n",
    "        return False\n",
    "\n",
    "def check_schema(table, expected_cols):\n",
    "    df = spark.table(table)\n",
    "    actual_cols = df.columns\n",
    "    return set(actual_cols) == set(expected_cols)\n",
    "\n",
    "def check_not_empty(table):\n",
    "    df = spark.table(table)\n",
    "    return not df.rdd.isEmpty()\n",
    "\n",
    "def check_column_types(table, expected_types):\n",
    "    df = spark.table(table)\n",
    "    actual_types = {field.name: field.dataType.simpleString() for field in df.schema.fields}\n",
    "    for col, expected_type in expected_types.items():\n",
    "        if col not in actual_types or actual_types[col] != expected_type:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "@pytest.mark.parametrize(\"table\", [table_name])\n",
    "def test_table_exists(table):\n",
    "    assert check_table_exists(table), f\"Table {table} should exist\"\n",
    "\n",
    "@pytest.mark.parametrize(\"table,expected_cols\", [(table_name, expected_columns)])\n",
    "def test_schema(table, expected_cols):\n",
    "    assert check_schema(table, expected_cols), f\"Schema of table {table} does not match expected\"\n",
    "\n",
    "@pytest.mark.parametrize(\"table\", [table_name])\n",
    "def test_not_empty(table):\n",
    "    assert check_not_empty(table), f\"Table {table} is empty\"\n",
    "\n",
    "@pytest.mark.parametrize(\"table,expected_types\", [(table_name, expected_schema_types)])\n",
    "def test_column_types(table, expected_types):\n",
    "    assert check_column_types(table, expected_types), f\"Column types of table {table} do not match expected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e2e92a6-6d1d-42ec-badb-8a5b24d4f924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Table exists:\", check_table_exists(table_name))\n",
    "print(\"Schema ok:\", check_schema(table_name, expected_columns))\n",
    "print(\"Type ok:\", check_column_types(table_name, expected_schema_types))\n",
    "print(\"Not empty:\", check_not_empty(table_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b478354a-36cf-47dc-81ad-a2ef599e5312",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    test_table_exists(table_name)\n",
    "    test_schema(table_name, expected_columns)\n",
    "    test_schema(table_name, expected_schema_types)\n",
    "    test_not_empty(table_name)\n",
    "    print(\"✅ Todos os testes passaram\")\n",
    "except AssertionError as e:\n",
    "    print(f\"❌ Falhou: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fine-test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
